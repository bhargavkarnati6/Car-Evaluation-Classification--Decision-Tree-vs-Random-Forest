üöó Car Evaluation Classification ‚Äî Decision Tree vs Random Forest (Custom + sklearn)

This notebook trains and evaluates three tree-based models on the UCI Car Evaluation dataset:
	1.	Decision Tree (sklearn)
	2.	Random Forest (sklearn)
	3.	MyRandomForest (custom implementation) ‚Äî built using:
	‚Ä¢	bootstrapping (sampling with replacement)
	‚Ä¢	multiple DecisionTreeClassifiers
	‚Ä¢	majority-vote aggregation

The notebook includes preprocessing, model training, evaluation metrics, and confusion matrices.

‚∏ª

üìå Dataset
	‚Ä¢	Dataset: Car Evaluation (UCI)
	‚Ä¢	Source: Loaded using ucimlrepo (dataset id = 19)
	‚Ä¢	Rows: 1,728
	‚Ä¢	Features: 6 categorical features
(buying, maint, doors, persons, lug_boot, safety)
	‚Ä¢	Target: class (4 classes: unacc, acc, good, vgood)

‚∏ª

‚öôÔ∏è What the Notebook Does

1) Load Data
	‚Ä¢	Fetches dataset using fetch_ucirepo(id=19)
	‚Ä¢	Separates features X and target y
	‚Ä¢	Plots class distribution (bar chart)

2) Preprocessing
	‚Ä¢	One-hot encodes all categorical features using pd.get_dummies()
	‚Ä¢	Splits into train/test with stratified sampling (80/20)

3) Train Models
	‚Ä¢	Trains a DecisionTreeClassifier
	‚Ä¢	Trains sklearn‚Äôs RandomForestClassifier
	‚Ä¢	Trains MyRandomForest (custom)

4) Evaluate

For each model, the notebook prints:
	‚Ä¢	Accuracy
	‚Ä¢	Classification report (precision/recall/F1)
	‚Ä¢	Confusion matrix plot

Finally, it prints a comparison table:
	‚Ä¢	Model name
	‚Ä¢	Accuracy

‚∏ª

üß† Custom Model: MyRandomForest

Your MyRandomForest class works like a simplified Random Forest:
	‚Ä¢	Bootstrapping: for each tree, sample n rows with replacement
	‚Ä¢	Train a DecisionTreeClassifier on each bootstrap sample
	‚Ä¢	Prediction: collect predictions from all trees and return the majority vote
	‚Ä¢	Also includes predict_proba() by averaging tree probabilities

‚∏ª

üõ†Ô∏è Tech Stack
	‚Ä¢	Python
	‚Ä¢	Pandas
	‚Ä¢	NumPy
	‚Ä¢	Matplotlib
	‚Ä¢	scikit-learn
	‚Ä¢	ucimlrepo
